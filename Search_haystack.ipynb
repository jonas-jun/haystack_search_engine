{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Search_haystack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNkGg1SQ+JEOp7SgxBHdPdF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonas-jun/haystack_search_engine/blob/main/Search_haystack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnfcshcG-Crs"
      },
      "source": [
        "# Building a Faster & Accurate CORD Search Engine\n",
        "\n",
        "Apr. 2021\n",
        "\n",
        "**Dataset**  \n",
        "COVID-19 Open Research Dataset Challenge (CORD-19)  \n",
        "An AI challenge with AI2, CZI, MSR, Georgetown, NIH & The White House\n",
        "[link](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge)\n",
        "\n",
        "\n",
        "**Reference**  \n",
        "Medium [link](https://medium.com/analytics-vidhya/building-a-faster-and-accurate-search-engine-on-custom-dataset-with-transformers-d1277bedff3d)  \n",
        "Kaggle notebook [link](https://www.kaggle.com/officialshivanandroy/building-faster-accurate-cord-search-engine)  \n",
        "Haystack github [link](https://github.com/deepset-ai/haystack)  \n",
        "Basic QA pipeline tutorial by Farm-Haystack [Colab link](https://colab.research.google.com/github/deepset-ai/haystack/blob/master/tutorials/Tutorial1_Basic_QA_Pipeline.ipynb#scrollTo=ENjEn8L4Y8Fo)  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdzprawl85Fn"
      },
      "source": [
        "## Explain\n",
        "\n",
        "**Total Structure**  \n",
        "pypi.org/project/farm-haystack  \n",
        "![Key components](https://warehouse-camo.ingress.cmh1.psfhosted.org/1e0b43ce96afebe6ad8436b361fc791398a810c2/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f646565707365742d61692f686179737461636b2f6d61737465722f646f63732f5f7372632f696d672f636f6e63657074735f686179737461636b5f76322e706e67)  \n",
        "github.com/deepset-ai/haystack\n",
        "![Key components github](https://raw.githubusercontent.com/deepset-ai/haystack/master/docs/_src/img/concepts_haystack_handdrawn.png)  \n",
        "  \n",
        "    \n",
        "    \n",
        "**Document Store**: Database storing the documents for our search.  \n",
        "![DocumentStore_github](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0f58b074-9e5a-4080-89be-b53bd2c37713%2Fdocument_store.jpg?table=block&id=981d43aa-cf84-46b9-96ef-3051862d7378&width=4520&userId=8202ecb5-2b7f-4cf4-a51f-002f5e64247c&cache=v2)\n",
        "- Elasticsearch\n",
        "- SQL\n",
        "- In-Memory\n",
        "- FAISS\n",
        "\n",
        "**Retriever**: Fast, simple algorithm that identifies candidate passages from a large collection of documents. (Document Store) Algorithms include TF-IDF or BM25, custom Elasticsearch queries, and embedding-based apporaches. The Retreiver helps to narrow down the scope for Reader.\n",
        "- TF-IDF: Term Frequency - Inverse Document Frequency\n",
        "- BM25\n",
        "\n",
        "**Reader**: Powerful neural model that reads through texts in detail to find an answer, like BERT, RoBERTa or XLNet trained via FARM or Transformers on SQuAD like tasks. It takes multiple texts as input and returns top-n answers with corresponding confidence scores. You can just load a pretrained model from Hugging Face's model hub or fine-tune it to your own domain data.\n",
        "\n",
        "**Pipeline**: glues together (\"Finder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwTkm5omc7Qk"
      },
      "source": [
        "## BM25 Algorithm\n",
        "\n",
        "- \"Okapi BM25\", Best Matching  \n",
        "- A ranking function used by search engines to esdtimate the relevance of documents to a given search query. [Wiki link](https://en.wikipedia.org/wiki/Okapi_BM25)  \n",
        "- Several modified ranking functions (BM11: b=1, BM15: b=0, BM25+: additional free parameter)\n",
        "\n",
        "![BM_1](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F78c6fe9f-aaff-404c-9be4-6090f4b282f2%2Fbm25_algorithm.jpg?table=block&id=dec383f4-4030-43d1-9bb1-d66b4437a6b8&width=1840&userId=8202ecb5-2b7f-4cf4-a51f-002f5e64247c&cache=v2)  \n",
        "![BM_2](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F616ebde9-95a9-4237-ac0e-bea2a3da2ea2%2FBM25_algorithm2.jpg?table=block&id=00d469d8-e92c-45f4-a928-a7146af64384&width=2420&userId=&cache=v2)  \n",
        "Components\n",
        "![BM_3](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F33ec9b8a-5911-45cd-aab9-ca8af8e5e100%2F_2021-04-02__1.16.49.png?table=block&id=e4ca495e-7af5-493f-a22b-365f6357fb04&width=2270&userId=&cache=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa0T5-NACpvp"
      },
      "source": [
        "## Prepare Haystack\n",
        "\n",
        "**What to build with Haystack**  \n",
        "- Ask questions in natural language and find granular answers in your documents.\n",
        "- Perform semantic search and retrieve documents according to meaning, not keywords\n",
        "- Use off-the-shelf models or fine-tune them to your domain.\n",
        "- Use user feedback to evaluate, benchmark, and continuously improve your live models.\n",
        "- Leverage existing knowledge bases and better handle the long tail of queries that chatbots receive.\n",
        "- Automate processes by automatically applying a list of questions to new documents and using the extracted answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjDW8_DlC7__"
      },
      "source": [
        "**For installation**  \n",
        "- from github !pip install git+https://github.com/deepset-ai/haystack.git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7JPMVLwGxQ6"
      },
      "source": [
        "!pip install git+https://github.com/deepset-ai/haystack.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93RN4Oe8HNVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0ab73c-6344-4b88-a43a-353022716599"
      },
      "source": [
        "from haystack import Finder\n",
        "from haystack.preprocessor.cleaning import clean_wiki_text #haystack.indexing -> haystack.preprocessor\n",
        "from haystack.preprocessor.utils import convert_files_to_dicts, fetch_archive_from_http\n",
        "from haystack.reader.farm import FARMReader\n",
        "from haystack.reader.transformers import TransformersReader\n",
        "from haystack.utils import print_answers"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/02/2021 04:56:10 - INFO - faiss.loader -   Loading faiss with AVX2 support.\n",
            "04/02/2021 04:56:10 - INFO - faiss.loader -   Loading faiss.\n",
            "04/02/2021 04:56:11 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4R5lwJht-ZVv"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "from json to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyZsdW17BZXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82ed941d-fc3e-4e55-9db4-d60ef368f97c"
      },
      "source": [
        "# for colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "GDRIVE_HOME = '/content/drive/MyDrive'\n",
        "FOLDER = 'GSDS/2021_1/Search_engine_Haystack/data_cord'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PsP6s32B1LB"
      },
      "source": [
        "# # read 50,000 docs to dataframe [id, title, abstract, full text]\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import os\n",
        "# import json\n",
        "# import re\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# dirs = ['pmc_json', 'pdf_json']\n",
        "# docs = list()\n",
        "# counts = list()\n",
        "\n",
        "# for d in dirs:\n",
        "#     print(d)\n",
        "#     counts = 0\n",
        "#     target_dir = os.path.join(GDRIVE_HOME, FOLDER, d)\n",
        "#     for f in tqdm(os.listdir(target_dir)):\n",
        "#         file_path = os.path.join(target_dir, f)\n",
        "#         j = json.load(open(file_path, 'rb'))\n",
        "#         paper_id = j['paper_id']\n",
        "#         paper_id = paper_id[-7:] # take last 7 characters for id\n",
        "#         title = j['metadata']['title']\n",
        "\n",
        "#         try: # no abstracts in some docs\n",
        "#             abstract = j['abstract'][0]['text']\n",
        "#         except:\n",
        "#             abstract = ''\n",
        "\n",
        "#         full_text = str()\n",
        "#         bib_entries = list()\n",
        "#         for text in j['body_text']:\n",
        "#             full_text += text['text']\n",
        "\n",
        "#         docs.append([paper_id, title, abstract, full_text])\n",
        "#         counts += 1\n",
        "#         if count >= 25000:\n",
        "#             break # only for 25000 files\n",
        "\n",
        "# df = pd.DataFrame(docs, columns=['paper_id', 'title', 'abstract', 'full_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_DnE0izNEZz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "c3cf27c7-12fd-4391-ef29-a8a60d412323"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "df = pd.read_csv(os.path.join(GDRIVE_HOME, FOLDER, 'processed.csv'))\n",
        "print('Shape of Dataframe: {}\\n'.format(df.shape))\n",
        "print('Information')\n",
        "print(df.info())\n",
        "print('\\nSamples')\n",
        "df.sample(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Dataframe: (50000, 4)\n",
            "\n",
            "Information\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   paper_id   50000 non-null  object\n",
            " 1   title      47432 non-null  object\n",
            " 2   abstract   17286 non-null  object\n",
            " 3   full_text  50000 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 1.5+ MB\n",
            "None\n",
            "\n",
            "Samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35618</th>\n",
              "      <td>2e559b1</td>\n",
              "      <td>Epitope-Based Immunome-Derived Vaccines: A Strategy for Improved Design and ...</td>\n",
              "      <td>Vaccine science has extended beyond genomics to proteomics and has come to a...</td>\n",
              "      <td>The availability of immunome-mining tools has fueled the design and developm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1919</th>\n",
              "      <td>7202459</td>\n",
              "      <td>Changing trends of ocular trauma in the time of COVID-19 pandemic</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To reduce the spread of the novel coronavirus (2019-nCoV), countries have pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14444</th>\n",
              "      <td>7478888</td>\n",
              "      <td>200 Years of Florence and the challenges of nursing practices\\nmanagement in...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The development of nursing faces different challenges concerning autonomy,\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48329</th>\n",
              "      <td>f1261cd</td>\n",
              "      <td>Application of Open-Source Software in Knowledge Graph Construction</td>\n",
              "      <td>Knowledge graph (KG), as a new type of knowledge representation, has gained ...</td>\n",
              "      <td>specific definition and representation of the knowledge based on graph could...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34335</th>\n",
              "      <td>082af2f</td>\n",
              "      <td>AIOSP -Association Internationale d'Orientation Scolaire et Professionnelle ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The aims of educational and vocational guidance are to assist students and a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      paper_id  ...                                                                        full_text\n",
              "35618  2e559b1  ...  The availability of immunome-mining tools has fueled the design and developm...\n",
              "1919   7202459  ...  To reduce the spread of the novel coronavirus (2019-nCoV), countries have pr...\n",
              "14444  7478888  ...  The development of nursing faces different challenges concerning autonomy,\\n...\n",
              "48329  f1261cd  ...  specific definition and representation of the knowledge based on graph could...\n",
              "34335  082af2f  ...  The aims of educational and vocational guidance are to assist students and a...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2rFe_gKizWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6a8ad8-50d2-44f3-d4d0-1352df975502"
      },
      "source": [
        "# remove null samples in those columns\n",
        "df = df.dropna(subset=['paper_id', 'title', 'full_text']) # add 'paper_id'\n",
        "df.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/02/2021 04:59:08 - INFO - numexpr.utils -   NumExpr defaulting to 2 threads.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 47432 entries, 0 to 49999\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   paper_id   47432 non-null  object\n",
            " 1   title      47432 non-null  object\n",
            " 2   abstract   16608 non-null  object\n",
            " 3   full_text  47432 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 1.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O55kawXKbr5S"
      },
      "source": [
        "## Set up DocumentStore\n",
        "\n",
        "*Haystack* finds answer to queries within the documents stored in a *DocumentStore*.  \n",
        "\n",
        "The current implementations of DocumentStore include *ElasticsearchDocumentStore*, *SQLDocumentStore*, *FAISSDocumentStore*, and *InMemoryDocumentStore*.  \n",
        "\n",
        "But they recommend *ElasticsearchDocumentStore* because as it comes preloaded with features like full-text queries, BM25 retrieval, and vector storage for text embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqvpQ2XjyLDj"
      },
      "source": [
        "# Recommended: Start Elasticsearch using Docker (basic, but manually download in colab)\n",
        "#! docker run -d -p 9200:9200 -e \"discovery.type=single-node\" elasticsearch:7.9.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FLaAQmNgvTd"
      },
      "source": [
        "! wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "! tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "! chown -R daemon:daemon elasticsearch-7.9.2\n",
        "# version change to 7.9.2 from 7.6\n",
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "es_server = Popen(['elasticsearch-7.9.2/bin/elasticsearch'],\n",
        "                   stdout=PIPE, stderr=STDOUT,\n",
        "                   preexec_fn=lambda: os.setuid(1)  # as daemon\n",
        "                  )\n",
        "# wait until ES has started\n",
        "! sleep 30"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp6yA8C_hapA",
        "outputId": "376be067-eb01-4e34-8cd1-5dadcec15b31"
      },
      "source": [
        "# Connect to Elasticsearch\n",
        "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore # file name changed from database to document_store\n",
        "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/02/2021 04:59:59 - INFO - elasticsearch -   HEAD http://localhost:9200/ [status:200 request:0.082s]\n",
            "04/02/2021 04:59:59 - INFO - elasticsearch -   PUT http://localhost:9200/document [status:200 request:0.348s]\n",
            "04/02/2021 05:00:00 - INFO - elasticsearch -   PUT http://localhost:9200/label [status:200 request:0.179s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfOD2quZ_qsJ"
      },
      "source": [
        "Change structure of the dataset (dicts list)\n",
        "\n",
        "1. [{'name': str, 'text': str}, {'name': str, 'text': str}, ...]\n",
        "2. [{'text': str, 'meta': {'name': str, ...}, ...] - recommend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9CZf6_VeSV7"
      },
      "source": [
        "# Structure 1\n",
        "modified = df[['title', 'full_text']].rename(columns={'title': 'name', 'full_text': 'text'})\n",
        "dicts_1 = modified.to_dict(orient='records')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enybAqH8AwiF"
      },
      "source": [
        "dicts_1[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ez02JYAA5S9"
      },
      "source": [
        "# Structure 2\n",
        "dicts_2 = list()\n",
        "\n",
        "for i in range(len(df['title'])):\n",
        "    data = df.iloc[i]\n",
        "    temp = dict()\n",
        "    temp['text'] = data['full_text']\n",
        "    temp['meta'] = {'name': data['title'], 'p_id': data['paper_id']}\n",
        "    dicts_2.append(temp)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo6NxVOFB3K7"
      },
      "source": [
        "dicts_2[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNLMcEKdiDPS"
      },
      "source": [
        "document_store.write_documents(dicts_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OznkfWOEbCi_"
      },
      "source": [
        "## Retriever\n",
        "- dense: get dense embeddings for query and passage using bi-encoder [github](https://github.com/deepset-ai/haystack/blob/master/haystack/retriever/dense.py)\n",
        "- sparse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hxsmob_KcdmY"
      },
      "source": [
        "from haystack.retriever.sparse import ElasticsearchRetriever\n",
        "retriever = ElasticsearchRetriever(document_store=document_store, top_k=10)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VeW1gyCcp74"
      },
      "source": [
        "##Reader\n",
        "\n",
        "FARMReader.train() for fine-tuning on own data [github](https://github.com/deepset-ai/haystack/tree/master/haystack/reader)  \n",
        "@params  \n",
        "data_dir, train_filename, dev_filename, test_filename, use_gpu, batch_size, n_epochs, learning_rate, max_seq_len, warmup_proportion, dev_split, evaluate_every, save_dir, num_processes, use_amp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iOXruc2cu4a"
      },
      "source": [
        "reader = FARMReader(model_name_or_path='deepset/roberta-base-squad2-covid',\n",
        "                    use_gpu=True,\n",
        "                    context_window_size=500) # length of answer context\n",
        "'''\n",
        "model_name_or_path: dir. of saved model or the name of a public model,\n",
        "e.g. 'bert-base-cased', 'deepset/bert-base-cased-squad2', 'distilbert-base-uncased-distilled-squad'.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzoA6wX2dCQr"
      },
      "source": [
        "## Finder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWvW_oVDdRLz"
      },
      "source": [
        "#finder = Finder(reader, retriever)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opWXQG4WdUHp"
      },
      "source": [
        "# updated version\n",
        "from haystack.pipeline import ExtractiveQAPipeline\n",
        "pipe = ExtractiveQAPipeline(reader, retriever)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RgmXX-6Bc68"
      },
      "source": [
        "## Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqTNN7HDdxhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63339598-90f1-4e3c-e1eb-794ea4b113f7"
      },
      "source": [
        "# You can configure how many candidates the reader and retriever shall return\n",
        "# The higher top_k_retriever, the better (but also the slower) your answers. \n",
        "prediction = pipe.run(query=\"what is the covid19 symptom?\", top_k_retriever=10, top_k_reader=3)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/02/2021 05:19:04 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.286s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.12 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.93 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.66 Batches/s]\n",
            "04/02/2021 05:19:08 - ERROR - farm.modeling.predictions -   Both start and end offsets should be 0: \n",
            "41658, 41658 with a no_answer. \n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.50 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.61 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.98 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.95 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.45 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.99 Batches/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tE7FMdYeLet",
        "outputId": "43c08a07-58cc-4401-c574-1cb4262881a4"
      },
      "source": [
        "print(type(prediction))\n",
        "print('\\n===== Minimal Answer =====')\n",
        "print_answers(results=prediction, details='minimal')\n",
        "print('\\n===== Number of Answers =====')\n",
        "print('{}, same with top_k_reader'.format(len(prediction['answers'])))\n",
        "print('\\n===== Answer Structure =====')\n",
        "print(prediction['answers'][0].keys())\n",
        "print('\\n===== Meta Information =====')\n",
        "print(prediction['answers'][0]['meta'])\n",
        "print('\\n===== Length of Context =====')\n",
        "print(len(prediction['answers'][-1]['context']))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "\n",
            "===== Minimal Answer =====\n",
            "[   {   'answer': 'the most common symptom was dizziness (16.8%) followed '\n",
            "                  'closely by headache (13.1%)',\n",
            "        'context': 'airment, neuropathic pain, Guillain-Barre Syndrome and '\n",
            "                   'variants), and skeletal muscular injury 2 . In one '\n",
            "                   'observational study from Wuhan, of the 36.4% of COVID19 '\n",
            "                   'patients who showed neurologic manifestations, the most '\n",
            "                   'common symptom was dizziness (16.8%) followed closely by '\n",
            "                   'headache (13.1%) 2 . In another prospective analysis out '\n",
            "                   'of Wuhan, headache was present in 8% of all patients, '\n",
            "                   'overall the most common neurological symptom 1 . Neither '\n",
            "                   'of these studies collected data on milder nervous system '},\n",
            "    {   'answer': 'that fever was the most common initial symptom, followed by '\n",
            "                  'a cough, fatigue and shortness of breath',\n",
            "        'context': 'and 100% Negative Prediction when applying deep learning '\n",
            "                   'models on the detection of COVID19 from 260 X-Rays images. '\n",
            "                   'Yan, H.-T. Zhang, Yang Xiao, et al. (2020) analysed '\n",
            "                   'patients with COVID19 and found that fever was the most '\n",
            "                   'common initial symptom, followed by a cough, fatigue and '\n",
            "                   'shortness of breath. They used over 300 variables and '\n",
            "                   'found that lactic dehydrogenase, lymphocyte and '\n",
            "                   'high-sensitivity C-reactive protein were key clinical '\n",
            "                   'features. Chen et al. (2020) analysed the clinical '\n",
            "                   'characterist'},\n",
            "    {   'answer': 'headache as a symptom',\n",
            "        'context': 'rticles shared on social media relevant to this topic were '\n",
            "                   'also collected and considered for this review. Here, we '\n",
            "                   'aim to provide aThis article is protected by copyright. '\n",
            "                   'All rights reserved brief summary regarding COVID19 as it '\n",
            "                   'relates to headache as a symptom, headache as a disease, '\n",
            "                   'and headache medicine practice in areas with high COVID19 '\n",
            "                   'prevalence.Respiratory viruses in general can cause '\n",
            "                   'neurologic symptoms with headache being among the most '\n",
            "                   'common (alongside encephalopathy, seizure, and en'}]\n",
            "\n",
            "===== Number of Answers =====\n",
            "3, same with top_k_reader\n",
            "\n",
            "===== Answer Structure =====\n",
            "dict_keys(['answer', 'score', 'probability', 'context', 'offset_start', 'offset_end', 'offset_start_in_doc', 'offset_end_in_doc', 'document_id', 'meta'])\n",
            "\n",
            "===== Meta Information =====\n",
            "{'p_id': '07cb005', 'name': 'TITLE PAGE COVID19 and Headache: A Primer for Trainees Authors'}\n",
            "\n",
            "===== Length of Context =====\n",
            "500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN0o6jFkKYl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12085499-cb1b-48a1-9731-ea56c4c37d84"
      },
      "source": [
        "prediction = pipe.run(query=\"what is the impact of coronavirus on pregnant women?\", top_k_retriever=10, top_k_reader=2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/02/2021 05:20:09 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.090s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.90 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.96 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.29 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.97 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.54 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.26 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.55 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.56 Batches/s]\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.58 Batches/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNcLO0GBBkDB",
        "outputId": "ecd296c0-3b47-4895-877b-27ac07dd3e60"
      },
      "source": [
        "print(type(prediction))\n",
        "print('\\n===== Medium Answer =====')\n",
        "print_answers(results=prediction, details='medium')\n",
        "print('\\n===== Number of Answers =====')\n",
        "print('{}, same with top_k_reader'.format(len(prediction['answers'])))\n",
        "print('\\n===== Answer Structure =====')\n",
        "print(prediction['answers'][0].keys())\n",
        "print('\\n===== Meta Information =====')\n",
        "print(prediction['answers'][0]['meta'])\n",
        "print('\\n===== Length of Context =====')\n",
        "print(len(prediction['answers'][-1]['context']))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "\n",
            "===== Minimal Answer =====\n",
            "[   {   'answer': 'pregnant women are not prone to experiencing higher levels '\n",
            "                  'of stress and anxiety in comparison to non-pregnant '\n",
            "                  'controls',\n",
            "        'context': 'TSD development in vulnerable individuals [3] .Pregnancy '\n",
            "                   'is a rewarding yet challenging period of life, which '\n",
            "                   'demands physical, psychological and social adjustment to a '\n",
            "                   'new role. In general, pregnant women are not prone to '\n",
            "                   'experiencing higher levels of stress and anxiety in '\n",
            "                   'comparison to non-pregnant controls [4, 5] . Nevertheless, '\n",
            "                   'women with complicated pregnancies report higher levels of '\n",
            "                   'anxiety symptoms compared to low-risk pregnant subjects '\n",
            "                   '[6, 7] . Literature data on the impact of COVID-19 ',\n",
            "        'score': 14.60550308227539},\n",
            "    {   'answer': 'pregnant women were seven times more likely to suffer '\n",
            "                  'severe influenza-associated complications and twice as '\n",
            "                  'likely to die than non-pregnant women',\n",
            "        'context': 'elderly, pregnant women, children under 5 years, '\n",
            "                   'individuals with chronic medical and immunosuppressive '\n",
            "                   'conditions, and healthcare workers [106]. During the 2009 '\n",
            "                   'H1N1 pandemic, pregnant women were seven times more likely '\n",
            "                   'to suffer severe influenza-associated complications and '\n",
            "                   'twice as likely to die than non-pregnant women [38]. '\n",
            "                   'Furthermore, one study showed that of all women '\n",
            "                   'hospitalised during the first wave of the H1N1 pandemic in '\n",
            "                   'California, 42.6% were either pregnant or postpartum. A '\n",
            "                   'total o',\n",
            "        'score': 13.853385925292969}]\n",
            "\n",
            "===== Number of Answers =====\n",
            "2, same with top_k_reader\n",
            "\n",
            "===== Answer Structure =====\n",
            "dict_keys(['answer', 'score', 'probability', 'context', 'offset_start', 'offset_end', 'offset_start_in_doc', 'offset_end_in_doc', 'document_id', 'meta'])\n",
            "\n",
            "===== Meta Information =====\n",
            "{'p_id': '6e44e9e', 'name': 'Stress and Anxiety Levels in Pregnant and Post-Partum Women during the COVID-19 Pandemic'}\n",
            "\n",
            "===== Length of Context =====\n",
            "500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpmgvc3ZBmfk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}